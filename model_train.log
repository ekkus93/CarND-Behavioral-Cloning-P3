_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 32, 32, 16)        592       
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 16)        2320      
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 16)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 32)        4640      
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 16, 16, 32)        9248      
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 32)        0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 8, 8, 64)          18496     
_________________________________________________________________
leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 64)          0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 8, 8, 64)          36928     
_________________________________________________________________
leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 64)          0         
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 4, 4, 64)          0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 4, 4, 64)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 256)               262400    
_________________________________________________________________
leaky_re_lu_7 (LeakyReLU)    (None, 256)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 257       
=================================================================
Total params: 334,881
Trainable params: 334,881
Non-trainable params: 0
_________________________________________________________________
None

Epoch 1/20
Epoch 00001: val_loss improved from inf to 0.03094, saving model to data/model.h5
 - 28s - loss: 0.0325 - val_loss: 0.0309
Epoch 2/20
Epoch 00002: val_loss improved from 0.03094 to 0.02828, saving model to data/model.h5
 - 26s - loss: 0.0302 - val_loss: 0.0283
Epoch 3/20
Epoch 00003: val_loss improved from 0.02828 to 0.02664, saving model to data/model.h5
 - 26s - loss: 0.0280 - val_loss: 0.0266
Epoch 4/20
Epoch 00004: val_loss improved from 0.02664 to 0.02535, saving model to data/model.h5
 - 26s - loss: 0.0267 - val_loss: 0.0253
Epoch 5/20
Epoch 00005: val_loss improved from 0.02535 to 0.02483, saving model to data/model.h5
 - 26s - loss: 0.0247 - val_loss: 0.0248
Epoch 6/20
Epoch 00006: val_loss improved from 0.02483 to 0.02471, saving model to data/model.h5
 - 26s - loss: 0.0258 - val_loss: 0.0247
Epoch 7/20
Epoch 00007: val_loss improved from 0.02471 to 0.02430, saving model to data/model.h5
 - 26s - loss: 0.0238 - val_loss: 0.0243
Epoch 8/20
Epoch 00008: val_loss improved from 0.02430 to 0.02418, saving model to data/model.h5
 - 26s - loss: 0.0246 - val_loss: 0.0242
Epoch 9/20
Epoch 00009: val_loss did not improve
 - 26s - loss: 0.0233 - val_loss: 0.0243
Epoch 10/20
Epoch 00010: val_loss did not improve
 - 26s - loss: 0.0245 - val_loss: 0.0242
Epoch 11/20
Epoch 00011: val_loss did not improve
 - 26s - loss: 0.0252 - val_loss: 0.0242
Epoch 12/20
Epoch 00012: val_loss improved from 0.02418 to 0.02398, saving model to data/model.h5
 - 26s - loss: 0.0235 - val_loss: 0.0240
Epoch 13/20
Epoch 00013: val_loss did not improve
 - 26s - loss: 0.0228 - val_loss: 0.0242
Epoch 14/20
Epoch 00014: val_loss did not improve
 - 26s - loss: 0.0244 - val_loss: 0.0241
Epoch 15/20
Epoch 00015: val_loss improved from 0.02398 to 0.02379, saving model to data/model.h5
 - 26s - loss: 0.0226 - val_loss: 0.0238
Epoch 16/20
Epoch 00016: val_loss did not improve
 - 26s - loss: 0.0231 - val_loss: 0.0240
Epoch 17/20
Epoch 00017: val_loss did not improve
 - 26s - loss: 0.0241 - val_loss: 0.0241
Epoch 18/20
Epoch 00018: val_loss did not improve
 - 26s - loss: 0.0236 - val_loss: 0.0239
Epoch 19/20
Epoch 00019: val_loss did not improve
 - 26s - loss: 0.0228 - val_loss: 0.0242
Epoch 20/20
Epoch 00020: val_loss improved from 0.02379 to 0.02360, saving model to data/model.h5
 - 26s - loss: 0.0225 - val_loss: 0.0236
test loss: 0.023605
