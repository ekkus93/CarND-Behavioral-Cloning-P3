_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 32, 32, 8)         80        
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 8)         0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 8)         584       
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 8)         0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 16, 16, 8)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 16)        1168      
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 16)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 16, 16, 16)        2320      
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 16)        0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 8, 8, 16)          0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 8, 8, 32)          4640      
_________________________________________________________________
leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 8, 8, 32)          9248      
_________________________________________________________________
leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 32)          0         
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 4, 4, 32)          0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 4, 4, 32)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 512)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
leaky_re_lu_7 (LeakyReLU)    (None, 256)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 257       
=================================================================
Total params: 149,625
Trainable params: 149,625
Non-trainable params: 0
_________________________________________________________________
None

Epoch 1/10
Epoch 00001: val_loss improved from inf to 0.02539, saving model to data/model.h5
 - 26s - loss: 0.0296 - val_loss: 0.0254
Epoch 2/10
Epoch 00002: val_loss improved from 0.02539 to 0.02486, saving model to data/model.h5
 - 22s - loss: 0.0274 - val_loss: 0.0249
Epoch 3/10
Epoch 00003: val_loss improved from 0.02486 to 0.02416, saving model to data/model.h5
 - 23s - loss: 0.0267 - val_loss: 0.0242
Epoch 4/10
Epoch 00004: val_loss improved from 0.02416 to 0.02386, saving model to data/model.h5
 - 22s - loss: 0.0262 - val_loss: 0.0239
Epoch 5/10
Epoch 00005: val_loss improved from 0.02386 to 0.02350, saving model to data/model.h5
 - 23s - loss: 0.0264 - val_loss: 0.0235
Epoch 6/10
Epoch 00006: val_loss did not improve
 - 22s - loss: 0.0278 - val_loss: 0.0243
Epoch 7/10
Epoch 00007: val_loss improved from 0.02350 to 0.02340, saving model to data/model.h5
 - 22s - loss: 0.0257 - val_loss: 0.0234
Epoch 8/10
Epoch 00008: val_loss did not improve
 - 22s - loss: 0.0252 - val_loss: 0.0236
Epoch 9/10
Epoch 00009: val_loss did not improve
 - 23s - loss: 0.0261 - val_loss: 0.0235
Epoch 10/10
Epoch 00010: val_loss did not improve
 - 22s - loss: 0.0247 - val_loss: 0.0235
test loss: 0.023400
