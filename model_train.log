_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 128, 128, 8)       224       
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 8)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 128, 128, 8)       584       
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 128, 128, 8)       0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 64, 64, 8)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 64, 64, 16)        1168      
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 64, 64, 16)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 64, 64, 16)        2320      
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 64, 64, 16)        0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 32, 32, 32)        4640      
_________________________________________________________________
leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 32)        0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 32, 32, 32)        9248      
_________________________________________________________________
leaky_re_lu_6 (LeakyReLU)    (None, 32, 32, 32)        0         
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 16, 16, 64)        18496     
_________________________________________________________________
leaky_re_lu_7 (LeakyReLU)    (None, 16, 16, 64)        0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 16, 16, 64)        36928     
_________________________________________________________________
leaky_re_lu_8 (LeakyReLU)    (None, 16, 16, 64)        0         
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 8, 8, 128)         73856     
_________________________________________________________________
leaky_re_lu_9 (LeakyReLU)    (None, 8, 8, 128)         0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 8, 8, 128)         147584    
_________________________________________________________________
leaky_re_lu_10 (LeakyReLU)   (None, 8, 8, 128)         0         
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 4, 4, 128)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 2048)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 256)               524544    
_________________________________________________________________
leaky_re_lu_11 (LeakyReLU)   (None, 256)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 257       
=================================================================
Total params: 819,849
Trainable params: 819,849
Non-trainable params: 0
_________________________________________________________________
None

Epoch 1/30
Epoch 00001: val_loss improved from inf to 0.02254, saving model to data/model.h5
 - 65s - loss: 0.0278 - val_loss: 0.0225
Epoch 2/30
Epoch 00002: val_loss improved from 0.02254 to 0.02194, saving model to data/model.h5
 - 62s - loss: 0.0244 - val_loss: 0.0219
Epoch 3/30
Epoch 00003: val_loss improved from 0.02194 to 0.02190, saving model to data/model.h5
 - 62s - loss: 0.0235 - val_loss: 0.0219
Epoch 4/30
Epoch 00004: val_loss improved from 0.02190 to 0.02160, saving model to data/model.h5
 - 62s - loss: 0.0244 - val_loss: 0.0216
Epoch 5/30
Epoch 00005: val_loss improved from 0.02160 to 0.02141, saving model to data/model.h5
 - 62s - loss: 0.0238 - val_loss: 0.0214
Epoch 6/30
Epoch 00006: val_loss improved from 0.02141 to 0.02136, saving model to data/model.h5
 - 62s - loss: 0.0231 - val_loss: 0.0214
Epoch 7/30
Epoch 00007: val_loss did not improve
 - 61s - loss: 0.0228 - val_loss: 0.0214
Epoch 8/30
Epoch 00008: val_loss did not improve
 - 61s - loss: 0.0226 - val_loss: 0.0214
Epoch 9/30
Epoch 00009: val_loss did not improve
 - 61s - loss: 0.0205 - val_loss: 0.0218
Epoch 10/30
Epoch 00010: val_loss improved from 0.02136 to 0.02084, saving model to data/model.h5
 - 62s - loss: 0.0220 - val_loss: 0.0208
Epoch 11/30
Epoch 00011: val_loss did not improve
 - 61s - loss: 0.0213 - val_loss: 0.0210
Epoch 12/30
Epoch 00012: val_loss did not improve
 - 61s - loss: 0.0197 - val_loss: 0.0209
Epoch 13/30
Epoch 00013: val_loss improved from 0.02084 to 0.02004, saving model to data/model.h5
 - 62s - loss: 0.0192 - val_loss: 0.0200
Epoch 14/30
Epoch 00014: val_loss did not improve
 - 61s - loss: 0.0189 - val_loss: 0.0212
Epoch 15/30
Epoch 00015: val_loss did not improve
 - 61s - loss: 0.0173 - val_loss: 0.0203
Epoch 16/30
Epoch 00016: val_loss did not improve
 - 61s - loss: 0.0177 - val_loss: 0.0201
Epoch 17/30
Epoch 00017: val_loss improved from 0.02004 to 0.01989, saving model to data/model.h5
 - 62s - loss: 0.0162 - val_loss: 0.0199
Epoch 18/30
Epoch 00018: val_loss did not improve
 - 61s - loss: 0.0148 - val_loss: 0.0206
Epoch 19/30
Epoch 00019: val_loss did not improve
 - 61s - loss: 0.0153 - val_loss: 0.0202
Epoch 20/30
Epoch 00020: val_loss did not improve
 - 61s - loss: 0.0140 - val_loss: 0.0200
Epoch 21/30
Epoch 00021: val_loss did not improve
 - 61s - loss: 0.0133 - val_loss: 0.0200
Epoch 22/30
Epoch 00022: val_loss did not improve
 - 61s - loss: 0.0117 - val_loss: 0.0215
Epoch 23/30
Epoch 00023: val_loss did not improve
 - 61s - loss: 0.0114 - val_loss: 0.0204
Epoch 24/30
Epoch 00024: val_loss did not improve
 - 61s - loss: 0.0105 - val_loss: 0.0226
Epoch 25/30
Epoch 00025: val_loss did not improve
 - 61s - loss: 0.0107 - val_loss: 0.0202
Epoch 26/30
Epoch 00026: val_loss did not improve
 - 61s - loss: 0.0096 - val_loss: 0.0204
Epoch 27/30
Epoch 00027: val_loss did not improve
 - 61s - loss: 0.0096 - val_loss: 0.0214
Epoch 28/30
Epoch 00028: val_loss did not improve
 - 61s - loss: 0.0085 - val_loss: 0.0207
Epoch 29/30
Epoch 00029: val_loss did not improve
 - 61s - loss: 0.0078 - val_loss: 0.0205
Epoch 30/30
Epoch 00030: val_loss did not improve
 - 61s - loss: 0.0075 - val_loss: 0.0205
test loss: 0.019891
